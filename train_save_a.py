# -*- coding: utf-8 -*-
"""train_save_A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dslBiI_01dhKLYDZCdmuNqgFvTTwuQ-4
"""

from google.colab import drive
drive.mount('/content/drive')

# Second Code: Model Training and Evaluation
from transformers import ViTForImageClassification, ViTImageProcessor
from torch.utils.data import DataLoader
from PIL import Image
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import os

# Load preprocessed data
preprocessed_data_path = "/content/drive/MyDrive/Project/preprocessed_data"
train_data, train_labels = torch.load('/content/drive/MyDrive/Project/preprocessed_data/train_data.pt')
val_data, val_labels = torch.load('/content/drive/MyDrive/Project/preprocessed_data/val_data.pt')
test_data, test_labels = torch.load('/content/drive/MyDrive/Project/preprocessed_data/test_data.pt')

print(f"Train Data Loaded: {train_data.shape}, Labels: {train_labels.shape}")
print(f"Validation Data Loaded: {val_data.shape}, Labels: {val_labels.shape}")
print(f"Test Data Loaded: {test_data.shape}, Labels: {test_labels.shape}")

# DataLoaders
batch_size = 32
train_loader = DataLoader(list(zip(train_data, train_labels)), batch_size=batch_size, shuffle=True)
val_loader = DataLoader(list(zip(val_data, val_labels)), batch_size=batch_size, shuffle=False)
test_loader = DataLoader(list(zip(test_data, test_labels)), batch_size=batch_size, shuffle=False)

folders=['tungro', 'brown_spot', 'bacterial_leaf_blight',
         'bacterial_leaf_streak', 'blast', 'downy_mildew',
         'dead_heart', 'hispa', 'normal', 'bacterial_panicle_blight']

# Model Setup
model = ViTForImageClassification.from_pretrained("google/vit-large-patch16-224-in21k", num_labels=len(folders))

for name, param in model.named_parameters():
    if "classifier" in name or "encoder.layer.23" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False



# Training Function
def train_model(model, train_loader, val_loader, epochs=15, learning_rate=3e-4):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    loss_fn = torch.nn.CrossEntropyLoss()

    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []

    for epoch in range(epochs):
        model.train()
        train_loss, correct, total = 0.0, 0, 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(pixel_values=images)
            loss = loss_fn(outputs.logits, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            preds = torch.argmax(outputs.logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        avg_train_loss = train_loss / len(train_loader)
        train_accuracy = correct / total
        train_losses.append(avg_train_loss)
        train_accuracies.append(train_accuracy)

        # Validation
        model.eval()
        val_loss, correct_val, total_val = 0.0, 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(pixel_values=images)
                loss = loss_fn(outputs.logits, labels)
                val_loss += loss.item()
                preds = torch.argmax(outputs.logits, dim=1)
                correct_val += (preds == labels).sum().item()
                total_val += labels.size(0)

        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = correct_val / total_val
        val_losses.append(avg_val_loss)
        val_accuracies.append(val_accuracy)

        print(f"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}")

    # Plot Loss and Accuracy
    output_dir = "/content/drive/MyDrive/Project/model_1"
    os.makedirs(output_dir, exist_ok=True)

    plt.figure()
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.legend()
    plt.title('Loss over Epochs')
    plt.savefig(os.path.join(output_dir, 'loss_plot.png'))

    plt.figure()
    plt.plot(train_accuracies, label='Train Accuracy')
    plt.plot(val_accuracies, label='Val Accuracy')
    plt.legend()
    plt.title('Accuracy over Epochs')
    plt.savefig(os.path.join(output_dir, 'accuracy_plot.png'))

    return model

output_dir = "/content/drive/MyDrive/Project/model_1"

trained_model = train_model(model, train_loader, val_loader)

# Save Model
torch.save(trained_model.state_dict(), os.path.join(output_dir, "paddy_disease_classifier_final.pt"))
print("Model saved successfully.")

from google.colab import drive
drive.mount('/content/drive')

# Second Code: Model Training and Evaluation
from transformers import ViTForImageClassification, ViTImageProcessor
from torch.utils.data import DataLoader
from PIL import Image
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import os

test_data, test_labels = torch.load('/content/drive/MyDrive/Project/preprocessed_data/test_data.pt')

batch_size=32
test_loader = DataLoader(list(zip(test_data, test_labels)), batch_size=batch_size, shuffle=False)

from transformers import ViTForImageClassification
import torch
import os

# Define the path to the saved model
output_dir = "/content/drive/MyDrive/Project/model_1"
model_path = os.path.join(output_dir, "paddy_disease_classifier_final.pt")

# Define the number of labels (based on your confirmed mapping)
num_labels = 10  # Since we have 10 diseases

# Load the model architecture
trained_model = ViTForImageClassification.from_pretrained(
    "google/vit-large-patch16-224-in21k",
    num_labels=num_labels
)

# Load the saved weights
trained_model.load_state_dict(torch.load(model_path))
print("Model loaded successfully.")

# Move model to appropriate device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
trained_model.to(device)

# Evaluation
trained_model.eval()
predictions, true_labels = [], []

# Define the index-to-disease mapping
index_to_disease = {
    0: 'tungro',
    1: 'brown_spot',
    2: 'bacterial_leaf_blight',
    3: 'bacterial_leaf_streak',
    4: 'blast',
    5: 'downy_mildew',
    6: 'dead_heart',
    7: 'hispa',
    8: 'normal',
    9: 'bacterial_panicle_blight'
}

# Create a list of disease names in index order for easy use
disease_names = [index_to_disease[i] for i in range(len(index_to_disease))]

# Ensure the device is defined
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
trained_model.to(device)
trained_model.eval()

predictions, true_labels = [],[]

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = trained_model(pixel_values=images)
        preds = torch.argmax(outputs.logits, dim=1)

        # Move predictions and labels to CPU for further processing
        predictions.extend(preds.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

from sklearn.metrics import classification_report
import pandas as pd

# Generate classification report with target names
report = classification_report(true_labels, predictions, target_names=disease_names, output_dict=True)

# Save the classification report to CSV
report_df = pd.DataFrame(report).transpose()
report_df.to_csv(os.path.join(output_dir, "classification_report_labeled.csv"))

# Display to verify
print(report_df)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Generate the confusion matrix
cm = confusion_matrix(true_labels, predictions)

# Plot the confusion matrix with disease names
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=disease_names, yticklabels=disease_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Disease')
plt.ylabel('Actual Disease')

# Save the confusion matrix
plt.savefig(os.path.join(output_dir, 'confusion_matrix_labeled.png'))
plt.close()

print("Evaluation completed and results saved.")

